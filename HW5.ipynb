{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "512f40fa",
   "metadata": {},
   "source": [
    "Question 1 :\n",
    "The null hypothesis is designed to be the baseline of the whole hypothesis test. The whole point of testing is to find out if the Null Hypothesis is correct or if we need to believe in another claim. An idea that can be examined and tested means that it can be proven false; it’s a hypothesis. A good null hypothesis needs to be precise and has data to support it. The null hypothesis is the claim that argues that there’s no effect or the original arguments given by the question. The alternative hypothesis is everything else. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248495c",
   "metadata": {},
   "source": [
    "Question 2 :\n",
    "The point of hypothesis tests is to estimate the population. \n",
    "Let me use an example to explain. Maybe we want to see if the average weight in Canada is around 70KG. We can’t measure the weight of every Canadian, so we only measure some of them, we called the group of people that we measured the sample, the whole Canadian population, the population. Every person inside the sample is denoted by Xi. We find the average weight among the sample; we call it the observed sample mean/average, denoted by ˉX. It has nothing to do with the population average (the average weight of every Canadian, μ). \n",
    "Now, let’s just conjure up a world where the average weight of all Canadians is 70KG based on our claim (μ0 = 70). Then, are you able to show me that the actual observed sample that we took earlier is still probable to be acquired from this hypothetical population? I mean, are there still chances that you can get that sample? If not, then logically, the world does not exist. Subsequently, the claim/hypothesis that the world is built around becomes unreliable. This is essentially the process of a hypothesis test using the p-value method. We are trying to use the sample to make sense of something in the population. Therefore, the outcomes definitely refer to the population. In this scenario, μ0 is the hypothetical population mean. μ0 is not the same as μ; it has not been verified.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6c626",
   "metadata": {},
   "source": [
    "Question 3 :\n",
    "I think that I might’ve answered this question in Question 2. If you argue that your null hypothesis is true, let it be true. We imagine that a world built according to the null hypothesis exists. If you argue that your null hypothesis is true, then you should be able to get a sample like the one we got from that hypothetical population. Furthermore, we calculate the probability of acquiring a sample like that from the population, and that’s our p-value. If the p-value is too low, then that means it’s almost impossible to find a sample from the unreal population. But my sample is real, my sample is taken accurately, therefore, I conclude that a world with such a null hypothesis does not exist. We reject the Null Hypothesis.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95375db6",
   "metadata": {},
   "source": [
    "Question 4 : \n",
    "I keep answering questions that I'm not supposed to. Haha. \n",
    "For example, let's say that my null hypothesis is that the average weight of Canadians is 70KG. I acquired a sample, and the average of that sample is 95KG. We use the steps to find the p-value (constructing a fake world where the null hypothesis is true) then we realize that the p-value, the probability of getting a sample where the mean is as or more extreme than 95KG in that hypothetical world is extremely low. That means there's  no way to get a sample where the mean = 95KG. However, since our sample is real, we can argue that the null hypothesis isn't real. It's too far from the actual observed data that we got; our assumption was too ridiculous. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88cc95d",
   "metadata": {},
   "source": [
    "Question 5 : \n",
    "Our H0 : no tendencies, 50/50, Probability = 50%, equal chance for left and right\n",
    "Our HA : != 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae655cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "population_parameter_value_under_H0 = 0.5\n",
    "\n",
    "observed_statistic = 0.645\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "number_of_simulations = 10000 \n",
    "n_size = 124 \n",
    "IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "\n",
    "# 0 means left, 1 means right \n",
    "for i in range(number_of_simulations):\n",
    "    \n",
    "    random_improvement = np.random.choice([0,1], size=n_size, replace=True)\n",
    "\n",
    "    IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "    # We constructed many samples of size 124\n",
    "    \n",
    "simulated_statistics = IncreaseProportionSimulations_underH0random\n",
    "\n",
    "SimulatedStats_as_or_more_extreme_than_ObservedStat = \\\n",
    "    abs(simulated_statistics - population_parameter_value_under_H0) >= \\\n",
    "    abs(observed_statistic - population_parameter_value_under_H0) \n",
    "# abs(observed_statistic - population_parameter_value_under_H0)  distance between observed_statistic and population_parameter...\n",
    "\n",
    "p_value = np.mean(SimulatedStats_as_or_more_extreme_than_ObservedStat)\n",
    "# How many samples is as or more extreme than the one we got. \n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf2406",
   "metadata": {},
   "source": [
    "p_value = 0.0015, 0.15%.\n",
    "We have strong evidence against the null hypothesis. Therefore, we reject the null hypothese. There are tendencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed07775",
   "metadata": {},
   "source": [
    "Question 6 : \n",
    "A smaller p-value indicates stronger evidence against the null hypothesis, but it does not definitely prove that the null hypothesis is wrong. No, it’s not possible to definitely prove that Fido is innocent, p-value itself can have type I and II errors. It’s also not possible to definitely prove that Fido is guilty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)  # Make simulation reproducible\n",
    "number_of_simulations = 10000  # Number of simulations to run\n",
    "n_size = len(patient_data)  # Size of the patient data\n",
    "IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "\n",
    "for i in range(number_of_simulations):\n",
    "    random_improvement = np.random.choice([0, 1], size=n_size, replace=True)\n",
    "    IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "\n",
    "observed_improvement = np.mean(patient_data)  # Example calculation\n",
    "\n",
    "# * * * * * * * * \n",
    "# Calculate p-value\n",
    "# The Change : \n",
    "p_value = np.mean(IncreaseProportionSimulations_underH0random >= observed_improvement)\n",
    "# We changed H0 = 50% to H0 >= 50%\n",
    "# Went from two side to one side\n",
    "'''\n",
    "In a two-tailed test, the alternative hypothesis considers both directions. Both sides of the distribution are considered. \n",
    "In a one-tailed test, the alternative hypothesis only considers one direction. \n",
    "As a result, the p-values for one-tailed tests are smaller. \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490cc9c",
   "metadata": {},
   "source": [
    "Question 8 : \n",
    "Introduction : The Fisher and Bristol experiment was designed to see if Bristol was guessing or if she was able to tell the difference in taste. It’s very similar to the one that we’re doing. \n",
    "\n",
    "The population is the STA130 students. The sample is the 80 students chosen from the population. Everyone is either correct (1) or wrong (0) about identifying the order in which the drink is made. The parameter of interest is the population mean. We would like to see if the mean = 0.5, indicating that there are equal chances of getting correct or incorrect on the test. The sample mean = (49 * 1) + (31 * 0) / 80 = 0.6125, this is the observed test statistic.\n",
    "\n",
    "Null Hypothesis : H0 : μ = 0.5 People couldn’t tell the order in which the tea and milk were added. Equal chance of guessing correctly or incorrectly. \n",
    "Alternative : No H0 : Ha : μ != 0.5 \n",
    "\n",
    "We are going to do sampling assuming that the null hypothesis is true. And examine the probability of getting our sample from the sampling distribution. Sample size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f975c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0439"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "population_parameter_value_under_H0 = 0.5\n",
    "\n",
    "observed_statistic = 0.6125\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "number_of_simulations = 10000 \n",
    "n_size = 80\n",
    "IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "\n",
    "# 0 means wrong guess, 1 means correct guess \n",
    "# Creating samples\n",
    "for i in range(number_of_simulations):\n",
    "    \n",
    "    # we generate a sample, sample size = 80, either 0 or 1\n",
    "    random_improvement = np.random.choice([0,1], size=n_size, replace=True)\n",
    "    IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "    \n",
    "# Now we have a distribution of samples, each of them has 80 values inside. Their mean indicates the percentages of them that got the order right. \n",
    "simulated_statistics = IncreaseProportionSimulations_underH0random\n",
    "\n",
    "SimulatedStats_as_or_more_extreme_than_ObservedStat = \\\n",
    "    abs(simulated_statistics - population_parameter_value_under_H0) >= \\\n",
    "    abs(observed_statistic - population_parameter_value_under_H0) \n",
    "# abs(observed_statistic - population_parameter_value_under_H0)  distance between observed_statistic and population_parameter...\n",
    "\n",
    "p_value = np.mean(SimulatedStats_as_or_more_extreme_than_ObservedStat)\n",
    "# How many samples is as or more extreme than the one we got. \n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5eebea",
   "metadata": {},
   "source": [
    "Question 8 :\n",
    "    the p_value = 0.0439, indicating that the probability of getting a mean as or more extreme than 0.6125 is 0.0439 assuming the null hypothesis.\n",
    "    P_value < 0.05, therefore, we have moderate evidence against the null hypothesis. We reject the Null hypothesis. Some people are able to tell the difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818bb9c",
   "metadata": {},
   "source": [
    "Question 9 : somewhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad130e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
